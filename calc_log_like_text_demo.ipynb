{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "import clip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yiJnSX19WY6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------\n",
        "# Setup Device and Load CLIP Model\n",
        "# -----------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load CLIP model and preprocessing pipeline\n",
        "model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
        "\n",
        "# -----------------------------------\n",
        "# Load Precomputed Mean and Whitening Matrix\n",
        "# -----------------------------------\n",
        "\n",
        "mean_path = 'mean_text_L14.pt'\n",
        "w_mat_path = 'w_mat_text_L14.pt'\n",
        "\n",
        "!wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=1BUZRTmLjWcnbLAiKsA3kGyMoiTNZVaZD\" -O w_mat_text_L14.pt\n",
        "!wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=1vvpVsGl-Ju3GiyyPxmOS2qERlCsCOto8\" -O mean_text_L14.pt\n",
        "\n",
        "# Load mean feature vector and whitening matrix\n",
        "mean_features = torch.load(mean_path, map_location=device, weights_only=False)\n",
        "w_mat = torch.load(w_mat_path, map_location=device, weights_only=False)\n",
        "\n",
        "# Number of features (dimensionality)\n",
        "N = len(mean_features)\n"
      ],
      "metadata": {
        "id": "2vXZMASiWcat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------\n",
        "# Define Captions for Log-Likelihood Computation\n",
        "# -----------------------------------\n",
        "captions = [\n",
        "    \"Donald Duck talking to Minney Mouse at Disney World at Christmas.\",\n",
        "    \"Donald Duck talking to a Mouse at Disney World at Christmas.\",\n",
        "    \"A Duck talking to Minney Mouse at Disney World at Christmas.\",\n",
        "    \"Donald Duck talking to Minney Mouse at Disney World.\",\n",
        "    \"Donald Duck talking to Minney Mouse at Christmas.\"\n",
        "]\n",
        "\n",
        "# Uncomment and modify the following captions for different experiments\n",
        "# captions = [\n",
        "#     \"A woman points a hair drier like it is a gun.\",\n",
        "#     \"An old woman points a hair drier like it is a gun.\",\n",
        "#     \"A bride points a hair drier like it is a gun.\",\n",
        "#     \"Jenny points a hair drier like it is a gun.\"\n",
        "# ]"
      ],
      "metadata": {
        "id": "zYNdyrFvWf2r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------\n",
        "# Process Each Caption and Compute Log-Likelihood\n",
        "# -----------------------------------\n",
        "for caption in captions:\n",
        "    # Tokenize the caption and move it to the correct device\n",
        "    text = clip.tokenize(caption).to(device)\n",
        "\n",
        "    # Encode the text into feature space\n",
        "    text_features = model.encode_text(text).to(device, dtype=torch.float32)\n",
        "\n",
        "    # Center and transform features using the whitening matrix\n",
        "    cntr_features = text_features - mean_features\n",
        "    w_features = torch.matmul(cntr_features, w_mat)\n",
        "\n",
        "    # Compute log-likelihood using Gaussian distribution assumption\n",
        "    log_like = -0.5 * (N * torch.log(torch.tensor(2 * torch.pi, device=device)) + torch.sum(w_features ** 2))\n",
        "\n",
        "    # Print log-likelihood\n",
        "    print(f'\\\"{caption}\\\" - Log Likelihood: {log_like.item():.2f}')\n"
      ],
      "metadata": {
        "id": "Tu0mUF8eWlJO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}