{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "import clip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yiJnSX19WY6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------\n",
        "# Setup Device and Load CLIP Model\n",
        "# -----------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load CLIP model and preprocessing pipeline\n",
        "model, preprocess = clip.load(\"ViT-L/14\", device=device)\n",
        "\n",
        "# -----------------------------------\n",
        "# Load Precomputed Mean and Whitening Matrix\n",
        "# -----------------------------------\n",
        "mean_path = 'mean_image_L14.pt'\n",
        "w_mat_path = 'w_mat_image_L14.pt'\n",
        "\n",
        "!wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=1fpdRdKjTg5FyhsbAPuP9D6gS5Xo-1b3n\" -O w_mat_image_L14.pt\n",
        "!wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=1XV04Ov7jsQnFc4MoBQop4flQFpRk-QyR\" -O mean_image_L14.pt\n",
        "\n",
        "# Load mean feature vector and whitening matrix\n",
        "mean_features = torch.load(mean_path, map_location=device, weights_only=False)\n",
        "w_mat = torch.load(w_mat_path, map_location=device, weights_only=False)\n",
        "\n",
        "# Number of features (dimensionality)\n",
        "N = len(mean_features)\n"
      ],
      "metadata": {
        "id": "2vXZMASiWcat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------\n",
        "# Load Images from Directory\n",
        "# -----------------------------------\n",
        "image_dir_path = 'images_hands'  # Directory containing images\n",
        "os.makedirs(image_dir_path, exist_ok=True)\n",
        "\n",
        "!wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=1WmhI93JzJijD9mEZLzLLfmBqAdwpsnqG\" -O images_hands/137106.jpg\n",
        "!wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=1s8uythPxDWq3ScmwI3umKN-Dc5NVFgtx\" -O images_hands/001385.jpg\n",
        "!wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=1NKnYI9gtJ3gHLAPZtff7hnLFei5b49Nn\" -O images_hands/001178.png\n",
        "!wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=1SP2gy3MX8MV2WWcdNT7i5hxgGiIYfjyV\" -O images_hands/000798.png\n",
        "\n",
        "image_names = os.listdir(image_dir_path)  # List all image filenames\n",
        "images_path = [os.path.join(image_dir_path, image) for image in image_names]  # Construct full paths"
      ],
      "metadata": {
        "id": "zYNdyrFvWf2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------\n",
        "# Process Images and Compute Log-Likelihood\n",
        "# -----------------------------------\n",
        "for image_path in images_path:\n",
        "    # Load and preprocess image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Extract CLIP features\n",
        "    image_features = model.encode_image(image_tensor).squeeze(0).to(device, dtype=torch.float32)\n",
        "\n",
        "    # Center the features and apply whitening transformation\n",
        "    cntr_features = image_features - mean_features\n",
        "    w_features = torch.matmul(cntr_features, w_mat)\n",
        "\n",
        "    # Compute log-likelihood\n",
        "    log_like = -0.5 * (N * torch.log(torch.tensor(2 * torch.pi, device=device)) + torch.sum(w_features**2))\n",
        "\n",
        "    # -----------------------------------\n",
        "    # Plot Image with Log-Likelihood\n",
        "    # -----------------------------------\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")  # Hide axis\n",
        "    plt.title(f\"Log-Likelihood: {log_like.item():.4f}\", fontsize=14, color='red')"
      ],
      "metadata": {
        "id": "Tu0mUF8eWlJO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}